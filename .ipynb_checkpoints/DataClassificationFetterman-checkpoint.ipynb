{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6812d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7621edd3",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180ee503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196926, 14)\n"
     ]
    }
   ],
   "source": [
    "fet = pd.read_csv('fettermanRaw.csv', parse_dates = [0])\n",
    "fet['date'] = fet.date.dt.date\n",
    "print(fet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "820d7d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'finiteautomata/bertweet-base-sentiment-analysis'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57857941",
   "metadata": {},
   "source": [
    "# Define important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c632b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Computes positive, negative, neutral, compound values for each tweet passed in the dataframe using SentimentAnalyzer and polarity using TextBlob\n",
    "'''\n",
    "\n",
    "def tweetScores(df, verbose = True):\n",
    "    '''\n",
    "    df with positive, negative, neutral, compound values for the content using SentimentAnalyzer and polarity using TextBlob\n",
    " \n",
    "    \n",
    "    Returns:\n",
    "        df with positive, negative, neutral, compound and polarity\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    \n",
    "    #Get the pos, neg and neu\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    df['rating'] = df['content'].apply(analyzer.polarity_scores)\n",
    "    df = pd.concat([df.drop(['rating'], axis=1), df['rating'].apply(pd.Series)], axis=1)\n",
    "    \n",
    "    #Get polarity and subjectivity\n",
    "    df['pol'] = df['content'].apply(lambda tweet: TextBlob(tweet).sentiment)\n",
    "    dfAux = df['pol'].apply(pd.Series)\n",
    "    dfAux.columns = ['polarity', 'subjectivity']\n",
    "    df = pd.concat([df.drop(['pol'], axis=1), dfAux], axis=1)\n",
    "            \n",
    "    return df\n",
    "\n",
    "'''\n",
    "Classify Tweets based on output of VADER SentimentAnalyzer\n",
    "'''\n",
    "\n",
    "def classifyTweets(df):\n",
    "    '''\n",
    "    Given a dataframe that already has columns neu, pos and neg, this classifies whether the tweet is positive, negative\n",
    "    or neutral.\n",
    "    \n",
    "    df (pd.DataFrame)\n",
    "    '''\n",
    "    \n",
    "    df['positive'] = 0\n",
    "    df['negative'] = 0\n",
    "    df['neutral'] = 0\n",
    "\n",
    "    df.loc[(df['pos'] > df['neg']), 'positive'] = 1\n",
    "\n",
    "    df.loc[(df['pos'] < df['neg']), 'negative'] = 1\n",
    "\n",
    "    df.loc[(df['pos'] == df['neg']), 'neutral'] = 1\n",
    "    \n",
    "    return df\n",
    "\n",
    "'''\n",
    "Loads the BERTTweetSentimentAnalysis Pre-trained model\n",
    "'''\n",
    "def createClassifier(model_name = model_name, cuda = 0):\n",
    "    model = TFAutoModelForSequenceClassification.from_pretrained(model_name, from_pt=True, num_labels=3) \n",
    "    #from_pt=True, because this model only exists in PyTorch\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    # Combining tokenizer and model into one classifier\n",
    "    classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer, device = cuda)\n",
    "    return classifier\n",
    "\n",
    "'''\n",
    "Classify the tweets based on the BERTTweetSentimentAnalysis Pre-trained model\n",
    "'''\n",
    "\n",
    "def classifyTweetsBert(df, classifier):\n",
    "    # .apply and loop took the same amount of time\n",
    "    df = df.copy()\n",
    "    \n",
    "    label = []\n",
    "    prob = []\n",
    "    for idx, text in enumerate(df['content']):\n",
    "        result = classifier(text)[0]\n",
    "        label.append( result['label'] )\n",
    "        prob.append( result['score'] )\n",
    "\n",
    "    df['BERT_sentiment'] = label\n",
    "    df['BERT_prob'] = prob\n",
    "    \n",
    "    return df\n",
    "    \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8186513",
   "metadata": {},
   "source": [
    "# Start the analysis with TextBlob and nltk sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc42bd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fet = tweetScores(fet)\n",
    "fet = classifyTweets(fet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "980f0161",
   "metadata": {},
   "outputs": [],
   "source": [
    "fet.to_csv('fettermanClassified1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8233f1b",
   "metadata": {},
   "source": [
    "# Analyze with Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebef2d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"
     ]
    }
   ],
   "source": [
    "#Create the classifier\n",
    "classifier = createClassifier(cuda = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54320337",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (142 > 128). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13h 45min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fet = classifyTweetsBert(fet, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d842dfaf",
   "metadata": {},
   "source": [
    "# Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "376a7ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fet.to_csv('fettermanClassified2.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
